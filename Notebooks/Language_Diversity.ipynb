{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "new_columns = {\n",
    "    'Paper': 'Paper',\n",
    "    'Author': 'Authors',\n",
    "    'Notes': 'Notes',\n",
    "    'Language Justification Given Beyond Data Availabilituy? td means typological diversity': 'Language-Justification',\n",
    "    'Typologically diverse with definition': 'Typological-Diversity',\n",
    "    'Cultural Nuances notes': 'Cultural-Nuances-Notes',\n",
    "    'Cultural Nuances Mentioned?': 'Cultural-Nuances-Mentioned',\n",
    "    'Cultural Nuances Addressed outside of limitations section?': 'Cultural-Nuances-Addressed',\n",
    "    'Any discussion on the impact of model training data in relation to evaluation?': 'Impact-of-Training-Data',\n",
    "    'Language Coverage': 'Language-Coverage',\n",
    "    'Language Notes': 'Language-Notes',\n",
    "    'Task & Dataset Used': 'Task-and-Dataset-Used'\n",
    "}\n",
    "\n",
    "data = data.rename(columns=new_columns)\n",
    "\n",
    "iso_codes = {\n",
    "    \"English\": \"en\", \"French\": \"fr\", \"German\": \"de\", \"Spanish\": \"es\", \"Chinese\": \"zh\", \"Hindi\": \"hi\",\n",
    "    \"Russian\": \"ru\", \"Arabic\": \"ar\", \"Vietnamese\": \"vi\", \"Thai\": \"th\", \"Urdu\": \"ur\", \"Swahili\": \"sw\",\n",
    "    \"Finnish\": \"fi\", \"Bulgarian\": \"bg\", \"Catalan\": \"ca\", \"Portuguese\": \"pt\", \"Japanese\": \"ja\",\n",
    "    \"Italian\": \"it\", \"Korean\": \"ko\", \"Estonian\": \"et\", \"Telugu\": \"te\", \"Basque\": \"eu\", \"Indonesian\": \"id\",\n",
    "    \"Malay\": \"ms\", \"Haitian Creole\": \"ht\", \"Quechua\": \"qu\", \"Bengali\": \"bn\", \"Tamil\": \"ta\", \"Mandarin\": \"zh\",\n",
    "    \"Romanian\": \"ro\", \"Polish\": \"pl\", \"Turkish\": \"tr\", \"Malayalam\": \"ml\", \"Hinglish\": \"en\", \"Ukrainian\": \"uk\",\n",
    "    \"Czech\": \"cs\", \"Kannada\": \"kn\", \"Gujarati\": \"gu\", \"Oriya\": \"or\", \"Punjabi\": \"pa\", \"Assamese\": \"as\",\n",
    "    \"Greek\": \"el\", \"Marathi\": \"mr\", \"Burmese\": \"my\", \"Dutch\": \"nl\", \"Danish\": \"da\", \"Swedish\": \"sv\",\n",
    "    \"Icelandic\": \"is\", \"Luxembourgish\": \"lb\", \"Norwegian\": \"no\", \"Nepali\": \"ne\", \"Aymara\": \"ay\", \"Xhosa\": \"xh\",\n",
    "    \"Yoruba\": \"yo\", \"Zulu\": \"zu\", \"Afrikaans\": \"af\", \"Javanese\": \"jv\", \"Somali\": \"so\", \"isiZulu\": \"zu\",\n",
    "    \"Luganda\": \"lg\", \"Malagasy\": \"mg\", \"Nigerian Pidgin\": \"pcm\", \"Hausa\": \"ha\", \"Galician\": \"gl\", \"Asturian\": \"ast\",\n",
    "    \"Chinese Simplified\": \"zh\", \"Gitksan\": \"git\", \"Uspanteko\": \"usp\", \"Natugu\": \"ntu\", \"Tsez\": \"tse\", \"Wolof\": \"wo\",\n",
    "    \"Arapaho\": \"arp\", \"Bribri\": \"bzd\", \"Manchu\": \"mnc\", \"Southern Quechua\": \"qu\", \"and Chinese\": \"zh\",\n",
    "    \"Lugala\": \"lg\", \"Malagasay\": \"mg\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert language names to ISO codes\n",
    "def map_to_iso(languages):\n",
    "    mapped = []\n",
    "    for language in re.split(r',|\\n', languages):\n",
    "        # Clean the language name\n",
    "        clean_language = re.sub(r\"\\(.*?\\)|\\.\", \"\", language).strip()\n",
    "        # Map to ISO code if available, else keep the original name for verification later\n",
    "        iso_code = iso_codes.get(clean_language, clean_language)\n",
    "        mapped.append(iso_code)\n",
    "    return mapped\n",
    "\n",
    "data['Language-Coverage-ISO'] = data['Language-Coverage'].apply(map_to_iso)\n",
    "\n",
    "continent_mapping = {\n",
    "    \"en\": \"Europe\", \"fr\": \"Europe\", \"de\": \"Europe\", \"es\": \"Europe\", \"zh\": \"Asia\", \"hi\": \"Asia\",\n",
    "    \"ru\": \"Europe\", \"ar\": \"Asia\", \"vi\": \"Asia\", \"th\": \"Asia\", \"ur\": \"Asia\", \"sw\": \"Africa\",\n",
    "    \"fi\": \"Europe\", \"bg\": \"Europe\", \"ca\": \"Europe\", \"pt\": \"Europe\", \"ja\": \"Asia\", \"it\": \"Europe\",\n",
    "    \"ko\": \"Asia\", \"et\": \"Europe\", \"te\": \"Asia\", \"eu\": \"Europe\", \"id\": \"Asia\", \"ms\": \"Asia\",\n",
    "    \"ht\": \"North America\", \"qu\": \"South America\", \"bn\": \"Asia\", \"ta\": \"Asia\", \"pl\": \"Europe\",\n",
    "    \"tr\": \"Asia\", \"ml\": \"Asia\", \"uk\": \"Europe\", \"cs\": \"Europe\", \"kn\": \"Asia\", \"gu\": \"Asia\",\n",
    "    \"or\": \"Asia\", \"pa\": \"Asia\", \"as\": \"Asia\", \"el\": \"Europe\", \"mr\": \"Asia\", \"ne\": \"Asia\",\n",
    "    \"ay\": \"South America\", \"xh\": \"Africa\", \"yo\": \"Africa\", \"zu\": \"Africa\", \"af\": \"Africa\",\n",
    "    \"jv\": \"Asia\", \"so\": \"Africa\", \"lg\": \"Africa\", \"mg\": \"Africa\", \"pcm\": \"Africa\", \"ha\": \"Africa\",\n",
    "    \"gl\": \"Europe\", \"ast\": \"Europe\", \"nl\": \"Europe\", \"da\": \"Europe\", \"sv\": \"Europe\", \"is\": \"Europe\",\n",
    "    \"lb\": \"Europe\", \"no\": \"Europe\", \"git\": \"North America\", \"usp\": \"North America\", \"ntu\": \"Oceania\",\n",
    "    \"tse\": \"Asia\", \"wo\": \"Africa\", \"arp\": \"North America\", \"bzd\": \"Central America\", \"mnc\": \"Asia\"\n",
    "}\n",
    "\n",
    "papers_with_continents = []\n",
    "for paper in data['Language-Coverage-ISO']:\n",
    "    continents = [continent_mapping[lang] for lang in paper if lang in continent_mapping]\n",
    "    papers_with_continents.append(continents)\n",
    "\n",
    "most_frequent_continent = [\n",
    "    Counter(conts).most_common(1)[0][0] if conts else 'Unknown' for conts in papers_with_continents\n",
    "]\n",
    "\n",
    "colors = {\n",
    "    \"North America\": \"blue\", \"Europe\": \"green\", \"Asia\": \"red\", \"Africa\": \"yellow\", \"South America\": \"purple\",\n",
    "    \"Oceania\": \"cyan\", \"Central America\": \"magenta\", \"Unknown\": \"grey\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart color by most frequent continent\n",
    "bar_colors = [colors[continent] for continent in most_frequent_continent]\n",
    "\n",
    "# Function to count the number of languages per continent for each paper\n",
    "def count_continents(papers):\n",
    "    continent_counts = {continent: [] for continent in colors.keys()}\n",
    "    for paper in papers:\n",
    "        count = Counter(paper)\n",
    "        for continent in colors.keys():\n",
    "            continent_counts[continent].append(count.get(continent, 0))\n",
    "    return continent_counts\n",
    "\n",
    "continent_counts = count_continents(papers_with_continents)\n",
    "\n",
    "# Preparing data for stacked bar chart\n",
    "papers_indices = np.arange(len(data))\n",
    "bottom = np.zeros(len(data))\n",
    "\n",
    "# Creating the stacked bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "for continent, counts in continent_counts.items():\n",
    "    plt.bar(papers_indices, counts, bottom=bottom, color=colors[continent], edgecolor='white', label=continent)\n",
    "    bottom += np.array(counts)\n",
    "\n",
    "plt.title('Number of Languages Covered by Each Paper with Continent Breakdown')\n",
    "plt.xlabel('Paper Number')\n",
    "plt.ylabel('Number of Languages')\n",
    "plt.xticks(papers_indices)\n",
    "plt.legend(title='Continent')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
